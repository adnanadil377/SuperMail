# LangGraph Email Agent - Studio Mode

## ğŸ¨ LangGraph Studio Setup

This project now supports **LangGraph Studio** for visual debugging and development!

### What is LangGraph Studio?

LangGraph Studio is a visual development environment that allows you to:
- ğŸ” **Visualize** your graph workflow in real-time
- ğŸ› **Debug** step-by-step execution
- ğŸ“Š **Monitor** state changes at each node
- ğŸ® **Test** interactively with different inputs
- ğŸ“ **Trace** the AI's reasoning process

## ğŸš€ Quick Start

### Option 1: LangGraph Studio (Visual Development) - **Recommended**

```powershell
# 1. Install LangGraph CLI
pip install -U langgraph-cli

# 2. Start LangGraph Studio
cd langgraph_server
langgraph dev
```

Then open: **http://localhost:8123**

You'll see:
- Visual graph representation
- Interactive input panel
- Real-time execution tracing
- State inspector at each node

### Option 2: FastAPI Server (Production Mode)

```powershell
cd langgraph_server
python main.py
```

API available at: **http://localhost:8001**

## ğŸ“ Project Structure

```
langgraph_server/
â”œâ”€â”€ langgraph.json      # LangGraph Studio configuration
â”œâ”€â”€ graph.py            # Main graph definition (Studio entry point)
â”œâ”€â”€ server.py           # Graph execution wrapper
â”œâ”€â”€ main.py             # FastAPI server (production)
â”œâ”€â”€ agent.py            # Legacy agent code (backup)
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ .env                # Configuration (API keys)
â””â”€â”€ AIEmailAgent.jsx    # React component
```

## ğŸ¯ Using LangGraph Studio

### 1. Start Studio
```powershell
cd langgraph_server
langgraph dev
```

### 2. Open Browser
Navigate to: http://localhost:8123

### 3. Test Your Graph

**Input Format:**
```json
{
  "messages": [],
  "user_input": "Send that I'm on leave for 5 days to my manager",
  "contacts": [],
  "intent": {},
  "emails_to_send": [],
  "user_token": "your_jwt_token",
  "user_id": 1
}
```

**Simplified Test (Studio will auto-populate):**
```json
{
  "user_input": "Send that I'm on leave for 5 days to my manager",
  "user_token": "your_jwt_token",
  "user_id": 1
}
```

### 4. Watch the Magic! âœ¨

You'll see the graph execute through each node:
1. **fetch_contacts** - Retrieves contacts from backend
2. **analyze_intent** - AI analyzes the request
3. **compose_emails** - AI writes personalized emails
4. **send_emails** - Sends via Django backend

Each step shows:
- Input state
- Node execution
- Output state
- Any errors or logs

## ğŸ”§ Configuration

### langgraph.json

```json
{
  "dependencies": ["."],
  "graphs": {
    "email_agent": "./graph.py:graph"
  },
  "env": ".env"
}
```

- **dependencies**: Python packages to install
- **graphs**: Points to your graph export
- **env**: Environment variables file

### Environment Variables

`.env` file:
```env
GOOGLE_API_KEY=your_api_key_here
BACKEND_URL=http://127.0.0.1:8000
```

## ğŸ® Development Workflow

### 1. Visual Development (LangGraph Studio)

```powershell
# Start Studio
langgraph dev

# Edit graph.py
# Changes auto-reload in Studio
# Test immediately with visual feedback
```

### 2. Production Deployment

```powershell
# Start FastAPI server
python main.py

# Or deploy as Docker container
# Or use LangGraph Cloud
```

## ğŸŒŸ Features

### LangGraph Studio Mode
- âœ… Visual graph editor
- âœ… Step-by-step debugging
- âœ… State inspection
- âœ… Interactive testing
- âœ… Hot reload
- âœ… Execution tracing

### Production API Mode
- âœ… FastAPI REST API
- âœ… CORS enabled
- âœ… OpenAPI docs
- âœ… Health checks
- âœ… Error handling

## ğŸ“Š Graph Visualization

In LangGraph Studio, you'll see this flow:

```
START
  â†“
[fetch_contacts]
  â†“
[analyze_intent] â† Google Gemini AI
  â†“
[compose_emails] â† Google Gemini AI
  â†“
[send_emails]
  â†“
END
```

Each node is clickable and shows:
- Input/Output state
- Execution time
- Logs and prints
- Error traces

## ğŸ§ª Testing Examples

### Example 1: Leave Request
```json
{
  "user_input": "Send that I'm on leave for 5 days to my manager and colleagues",
  "user_token": "your_jwt_token",
  "user_id": 1
}
```

**Expected Flow:**
1. Fetches contacts â†’ finds 1 manager, 2 colleagues
2. Analyzes intent â†’ extracts "5 days leave"
3. Composes â†’ formal email for manager, friendly for colleagues
4. Sends â†’ 3 emails sent

### Example 2: Late Notice
```json
{
  "user_input": "Tell my manager I'll be late tomorrow",
  "user_token": "your_jwt_token",
  "user_id": 1
}
```

**Expected Flow:**
1. Fetches contacts â†’ finds manager
2. Analyzes intent â†’ "late tomorrow"
3. Composes â†’ short formal notification
4. Sends â†’ 1 email sent

## ğŸ”— Integration with Frontend

The React component works with both modes!

### Studio Mode (Development)
```jsx
// Points to Studio API
const STUDIO_URL = "http://localhost:8123";

// Or proxy through FastAPI
const API_URL = "http://localhost:8001/agent/send-email";
```

### Production Mode
```jsx
const API_URL = "http://localhost:8001/agent/send-email";
```

## ğŸ“¦ Deployment Options

### 1. Local Development
```powershell
langgraph dev  # Studio at :8123
# OR
python main.py # API at :8001
```

### 2. Docker Container
```dockerfile
FROM python:3.11
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "main.py"]
```

### 3. LangGraph Cloud
```powershell
langgraph deploy
```

## ğŸ› Debugging

### Studio Mode (Visual Debugging)
1. Set breakpoints in graph visualization
2. Inspect state at each node
3. See AI prompts and responses
4. Trace execution path
5. View timing information

### API Mode (Log Debugging)
```powershell
# Enable debug logging
python main.py

# Check logs
# Look for âœ“ and âœ— markers in output
```

## ğŸ“ˆ Performance Monitoring

In Studio, you can see:
- â±ï¸ Time per node
- ğŸ“Š State size at each step
- ğŸ”„ Number of LLM calls
- ğŸ’° Token usage (if configured)

## ğŸ” Security Notes

- ğŸ”‘ API keys stored in `.env` (not committed)
- ğŸ”’ JWT authentication required
- ğŸš« User isolation enforced
- ğŸ›¡ï¸ CORS properly configured

## ğŸ†š Studio vs API Mode

| Feature | Studio Mode | API Mode |
|---------|-------------|----------|
| Visual Debugging | âœ… | âŒ |
| Interactive Testing | âœ… | Via /docs |
| Hot Reload | âœ… | âŒ |
| Production Ready | âš ï¸ Dev only | âœ… |
| REST API | âœ… (built-in) | âœ… |
| Tracing | âœ… Visual | Logs only |
| Port | 8123 | 8001 |

## ğŸ’¡ Pro Tips

1. **Use Studio for Development**: Visual feedback is invaluable
2. **Test Edge Cases**: Try unusual inputs in Studio
3. **Monitor State Size**: Keep it manageable
4. **Check Logs**: Studio shows all print statements
5. **Hot Reload**: Edit graph.py and see changes instantly

## ğŸš¨ Troubleshooting

### "langgraph command not found"
```powershell
pip install -U langgraph-cli
```

### "Graph not found"
Check `langgraph.json` points to correct file:
```json
"graphs": {
  "email_agent": "./graph.py:graph"
}
```

### "Cannot connect to backend"
Ensure Django is running:
```powershell
cd ../backend
python manage.py runserver
```

### Studio won't start
```powershell
# Check port 8123 is free
netstat -ano | findstr :8123

# Try different port
langgraph dev --port 8124
```

## ğŸ“š Resources

- **LangGraph Docs**: https://python.langchain.com/docs/langgraph
- **LangGraph Studio**: https://github.com/langchain-ai/langgraph-studio
- **LangSmith**: https://smith.langchain.com (for tracing)

## ğŸ“ Next Steps

1. âœ… Start LangGraph Studio: `langgraph dev`
2. âœ… Test with different inputs
3. âœ… Modify graph.py and see live updates
4. âœ… Deploy to production: `python main.py`
5. âœ… Integrate with your frontend

---

**Happy coding with LangGraph Studio! ğŸš€**

For the old FastAPI-only mode, see `agent.py` (legacy backup).
